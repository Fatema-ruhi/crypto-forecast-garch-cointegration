---
title: "A Statistical Analysis using the GARCH model with cointegration to forecast the         cryptocurrencies"
author: "Fatema Ruhi"
date: '2022-05-09'
output: word_document
---
           .

                          
#Introduction
In this project, we have worked with two real data sets of 2161 Ethereum coin from August 8 , 2015 to June 6,2021 and 2991 Bitcoin from April 29,2013 to July 6,2021. we have applied several time series models fit the data and combined together to check the pairs trading and predict the future scenarios of these two cryptocurrencies in US stock market.Out of 10 variables in each data, worked on the Market Capitals for both datasets. Based on our final model, the result shows the 10 possible future values of Ethereum and Bitcoin. This project introduces the following time methods to evaluate and forecast our data: ACF, PACF plots , Jarque-Bera test, Ljung-Box test, ARIMA model, ARCH-LM test, GARCH model, Granger Causality test, Vector Autoregression test, Co-integration, Vector Error Correction model. As a final result, we have got the forecasted values: 0.0020562480, -0.0008457530, 0.0005765753, -0.0071496357,  -0.0074977738, -0.0068781308,  -0.0047343820, -0.0036086771, -0.0042591713, -0.0051936175 and -0.0009641956,  0.0014005428, 0.0021225484, -0.0020517702, -0.0025182914. -0.0044474730, -0.0023450862, -0.0015299276, -0.0014995981, -0.0021436895.

# Data and Methodologies
The data has been collected from https://www.kaggle.com/datasets/sudalairajkumar/cryptocurrencypricehistory?resource=download&select=coin_BinanceCoin.csv.The methods that are used to evaluate and forecast our data: ACF, PACF plots based on the time series model to check the serial correlation, Jarque-Bera test for skewness and kurtosis, Ljung-Box test for ARCH effect, EACF for possible lags, ARIMA model based on the lags,ARCH-LM test to check the volatility, GARCH model to analyze th volatitly of the model, Granger Causality test to estimate whether one time series is useful to predict another, Vector Autoregression test to predict multiple vriables, Co-integration to test the interrelation between the variables and  Vector Error Correction model  to test for the presence of a long-run relationship between variables.  
            
            
            #####Equation######
            
            
            
From the datasets, we have focused on the market capitals and computed the log return of the market capitals. By the Augmented Dicky Fuller test, we have decided that the data is not staitonary. In order to make to make it stationary, we computed the first difference of the log returns. After confirming the stationarity, we have created two ARIMA models. 

We have compared models for both data by taking different lags and selected the better one based on the lowest AIC. Since we have our model, we have created the GARCH models for each selected models. After checking the output, we have marged the log return of first difference data and proceed for Granger causality.Because, we have not found any causality between two variables, we have built the Vector Autoregressive model and Vector Error Correction model to predict more than one vairables and show the interrelation between them. In the meantime, wew have checked the co integration of of the combined data to identify the degree of sensitivity of two variables at the same time.

#Results and Discussion 

At first, we prepare the data by selecting the market cpatials and compute the log return of it.
```{r echo=FALSE, warning=FALSE}
# Reading data-1 into R
data_1 = read.csv("D:/SEMO MATH/Spring-22/MA-575 Time Series and Forcasting/coin_Bitcoin.csv", quote="\"", comment.char="")
# Reading data-2 into R
data_2<- read.csv("D:/SEMO MATH/Spring-22/MA-575 Time Series and Forcasting/coin_Ethereum.csv", quote="\"", comment.char="")
```


```{r echo=FALSE, warning=FALSE}
# Specifying the Market capital column from the datasets
Marketcap_1 = data_1$Marketcap
Marketcap_2 = data_2$Marketcap
```

```{r echo=FALSE, warning=FALSE}
# Taking the log-return of Market capital
log_return_1 = log(Marketcap_1+1)
log_return_2 = log(Marketcap_2+1)
```
Both plots of the time series model showing no seasonality. Because the curves and the fluctuations are not following any trend.

```{r echo=FALSE, warning=FALSE}
# Time series plots of log-return
plot_1 = ts(log_return_1, frequency=365, start =c(2013,1))
plot(plot_1)
plot_2 = ts(log_return_2, frequency=365, start =c(2015,1))
plot(plot_2)
```

In order to check the skewness and curtosis of the data, we do the Jarque-Berra test. For the JB test, the values of skewness and kurtosis are needed that can be found from the descriptiopn of the log returns.
```{r echo=FALSE, warning=FALSE}
# Finding Skewness and Kurtosis of the data
library(psych)
Desc_1 = na.omit(describe(log_return_1))
Desc_1
Desc_2 = na.omit(describe(log_return_1))
Desc_2
```
The values are respectively,
```{r echo=FALSE, warning=FALSE}
#JB test to check the normality and adequacy-volatility
skewness_1 = Desc_1$skew
skewness_1
kurtosis_1 = Desc_1$kurtosis
kurtosis_1
skewness_2 = Desc_2$skew
skewness_2
kurtosis_2 = Desc_2$kurtosis
kurtosis_2
```

```{r echo=FALSE, warning=FALSE}
skewness_exchange_rate_1 = (skewness_1)/sqrt(6/NROW(log_return_1))

kurtosis_exchange_rate_1 = (kurtosis_1)/sqrt(24/NROW(log_return_1))

skewness_exchange_rate_2 = (skewness_2)/sqrt(6/NROW(log_return_2))

kurtosis_exchange_rate_2 = (kurtosis_2)/sqrt(24/NROW(log_return_2))
```

By the hypothesis testing at 5% confidence interval, the null hypothesis is rejected since, 186.9368 and 134.9995 grater than .05. Hence, both results are showing that the data does not come from a normal distribution.

```{r echo=FALSE, warning=FALSE}
#JB test
JB_test_1 = abs(skewness_exchange_rate_1)*abs(skewness_exchange_rate_1) + abs(kurtosis_exchange_rate_1)*abs(kurtosis_exchange_rate_1)
JB_test_1

JB_test_2 = abs(skewness_exchange_rate_2)*abs(skewness_exchange_rate_2) + abs(kurtosis_exchange_rate_2)*abs(kurtosis_exchange_rate_2)
JB_test_2
```

By the ACF and PACF plots, there have serial correlations in both data and some significant lags are also visible. The possible  lags can be ARMA (1,1) for both data.

```{r echo=FALSE, warning=FALSE}
acf(plot_1)
pacf(plot_1)

acf(plot_2)
pacf(plot_2)
```

To make sure we  take the Ljung-Box test ( P-vaues > .05) which is also indicating they are serially correlated. Hence, we can say that the log returns have ARCH effect.

```{r echo=FALSE, warning=FALSE}
# Test for Serial Correlation
Box.test(log_return_1, lag = 12, type = "Ljung")
# Test for Serial Correlation
Box.test(log_return_2, lag = 12, type = "Ljung")
```

Now to check the stationarity of both log returns, we compute the ADF test. The P-values are greater than .05. Therefore the data have unit roots and non stationary.

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(urca) 
library(fUnitRoots)
adfTest(log_return_1, lags= 20)

adfTest(log_return_2, lags= 20)
```

Since, the data are non stationary, we need to compute the first difference and check the stationarity again. For the first difference of log return for first data we see by the ACF , PACF plots there is no trend in their lags and by the ADF test, P-value is greater than .05. Hence the both outputs are indicating the stationarity.

```{r echo=FALSE, message=FALSE, warning=FALSE}
log1_diff_1 = diff(log_return_1)
Dplot_1 = ts(log1_diff_1, frequency=365, start =c(2015,1))
acf(Dplot_1)
pacf(Dplot_1)
adfTest(log1_diff_1, lags = 20)
```

Following the previous way, we can say the same for the first difference of log return for the second data that stationarity is present in the data now.

```{r echo=FALSE, message=FALSE, warning=FALSE}
log2_diff_1 = diff(log_return_2)
adfTest(log2_diff_1, lags = 20)
Dplot_2 = ts(log2_diff_1, frequency=365, start =c(2015,1))
acf(Dplot_2)
pacf(Dplot_2)
```

The P value of the ARCH test of the difference of log returns are showing that ther are ARCH effect present. 

```{r echo=FALSE, message=FALSE, warning=FALSE}
#ARCH-LM test
library(FinTS)
ArchTest(log1_diff_1)

ArchTest(log2_diff_1)
```

Now that we know our datasets are serially correlated, stationary with ARCH effect, we need to find out the possible lags to build a model. We choose the EACF test to find out the lags. Both tests are indicating the probable (p,q) values are (1,1), (0,1) for the Bitcoin data and (1,1), (2,2) for the Ethereum data. 

```{r echo=FALSE, message=FALSE, warning=FALSE}
#selecting the p,q by eacf test
library(TSA)
eacf(log1_diff_1)
eacf(log2_diff_1)
```

By the (p,q) values we build the ARMA models and pick the best model by th lowest AIC. Since the ARIMA model with (1,1,1) has the lowest AIC, this is our preferable model for Bitcoin data.

```{r echo=FALSE, message=FALSE, warning=FALSE}
# model fit
model1_1 = arima(log1_diff_1, order = c(1,0,1))
model1_1

model1_2 = arima(log1_diff_1, order = c(0,0,1))
model1_2
```

Similarly for the Ethereum coin, we choose the ARIMA model with (1,1,1).

```{r echo=FALSE, message=FALSE, warning=FALSE}
model2_1 = arima(log2_diff_1, order = c(1,0,1))
model2_1

model2_4 = arima(log2_diff_1, order = c(2,0,2))
model2_4
```

To check the volatitily of the model, we build the GARCH model. For Bitcoin data, we have taken two models 
                ###EquTIONS######
Since, the Ljung-Box test showing th model is not adequate, we will check the residuals for the model.

```{r echo=FALSE, message=FALSE, warning=FALSE}
#fitting the GARCH model
library(fGarch)
gm_1 = garchFit( ~ garch(1,0,1), data = log1_diff_1, trace=T)
summary(gm_1)

m1=garchFit(~arma(1,1) +garch(1,0,1), data=log1_diff_1, trace=T)
summary(m1)
```

Following the previous process, we will check the residuals for this model too.

```{r echo=FALSE, message=FALSE, warning=FALSE}
gm_2 = garchFit( ~ garch(1,0,1), data = log2_diff_1, trace=T)
summary(gm_2)

m2=garchFit(~arma(1,1) +garch(1,0,1), data=log2_diff_1, trace=T)
summary(m2)
```

The p-values of the Box test is indicating that the residuals of the models are adequate. Hence, we can say that the models are also adequate.

```{r}
res=residuals(m1, standardize=T)
Box.test(res, 12, type='Ljung')

res_2=residuals(m2, standardize=T)
Box.test(res_2, 12, type='Ljung')
```


```{r echo=TRUE, warning=FALSE}
DATA = cbind(data_1$Marketcap, data_2$Marketcap)

DAT = data.frame(cbind(DATA, log1_diff_1, log2_diff_1))

DA = DAT[ ,c("log1_diff_1", "log2_diff_1")]
```

To check the Granger causality, we have combined the first dieference of both log returns and create a new dataset.By the vector Autoregressive model, we have selected the number of order for the new dataset which is 6.

```{r echo=TRUE, warning=FALSE}
library(vars)
VARselect(DA)
```

Now by order 6, we check the granger causality. By th hypothesis testing, the P-vlaue is indicating both log returns do not granger cause each other.

```{r echo=TRUE, warning=FALSE}
# Test for Granger Causality
library(lmtest)
grangertest(log1_diff_1 ~ log2_diff_1, order = 6, data = DAT)

grangertest(log2_diff_1 ~ log1_diff_1, order = 6, data = DAT)
```

Since there is no granger causality, by the rank of the matrix r, the test values are grater than the 5% confidence interval. Hence, we can conclude that there is a cointegrating relationship between the two variables.
```{r echo=TRUE, warning=FALSE}
Coint_t <- ca.jo(DA, ecdet = "const", type = "trace", K = 6, spec = "longrun")
summary(Coint_t)

Coint_e = ca.jo(DA, ecdet = "const", type = "eigen", K = 6, spec = "longrun")
summary(Coint_e)
```


```{r echo=TRUE, warning=FALSE}
library(tsDyn)
tb_eg = VECM(DA,  lag=6,   r= 1,   include="const")
summary(tb_eg)

tb_jo = VECM(DA,  lag=6,   r= 1,   include="const",   estim="ML")
summary(tb_jo)
```


```{r echo=TRUE, warning=FALSE}
t_eg = lineVar(DA,  lag=6,   r= 1,   model="VECM",   include="const")
summary(t_eg)

t_jo = lineVar(DA,  lag=6,   r= 1,   model="VECM", include="const",   estim="ML")
summary(t_jo)
```

```{r echo=TRUE, warning=FALSE}
VARrep(t_jo)
```

Now, our model is ready to predict the possible future values. By the vector error Correction model we forecast 10 probable values. From the plot, we can conclude that pairs trading is possible.

```{r echo=TRUE, warning=FALSE}
vecm.pred  =predict(tb_jo,  n.ahead=10)
vecm.pred
pt = ts(vecm.pred)
plot(pt)
```

#Conclusion
To put it in a nutshell, though the volatility of the models are not adequate, their residual volatility is adequate and later it ahs been shown that Bitcoin and Ethereum coin are co integrated. Hence the pairs trading between two coins also possible. By the forecasted values, the future investments can be decided. 

```{r eval=FALSE, warning=FALSE, include=FALSE}
# Reading data-1 into R
data_1 = read.csv("D:/SEMO MATH/Spring-22/MA-575 Time Series and Forcasting/coin_Bitcoin.csv", quote="\"", comment.char="")
# Reading data-2 into R
data_2<- read.csv("D:/SEMO MATH/Spring-22/MA-575 Time Series and Forcasting/coin_Ethereum.csv", quote="\"", comment.char="")
```


```{r eval=FALSE, warning=FALSE, include=FALSE}
# Specifying the Market capital column from the datasets
Marketcap_1 = data_1$Marketcap
Marketcap_2 = data_2$Marketcap
```

```{r eval=FALSE, warning=FALSE, include=FALSE}
# Taking the log-return of Market capital
log_return_1 = log(Marketcap_1+1)
log_return_2 = log(Marketcap_2+1)
```

```{r eval=FALSE, warning=FALSE, include=FALSE}
# Time series plots of log-return
plot_1 = ts(log_return_1, frequency=365, start =c(2013,1))
plot(plot_1)
plot_2 = ts(log_return_2, frequency=365, start =c(2015,1))
plot(plot_2)
```

```{r eval=FALSE, warning=FALSE, include=FALSE}
# Finding Skewness and Kurtosis of the data
library(psych)
Desc_1 = na.omit(describe(log_return_1))
Desc_1
Desc_2 = na.omit(describe(log_return_1))
Desc_2
```

```{r eval=FALSE, warning=FALSE, include=FALSE}
#JB test to check the normality and adequacy-volatility
skewness_1 = Desc_1$skew
skewness_1
kurtosis_1 = Desc_1$kurtosis
kurtosis_1
skewness_2 = Desc_2$skew
skewness_2
kurtosis_2 = Desc_2$kurtosis
kurtosis_2
```

```{r eval=FALSE, warning=FALSE, include=FALSE}
skewness_exchange_rate_1 = (skewness_1)/sqrt(6/NROW(log_return_1))

kurtosis_exchange_rate_1 = (kurtosis_1)/sqrt(24/NROW(log_return_1))

skewness_exchange_rate_2 = (skewness_2)/sqrt(6/NROW(log_return_2))

kurtosis_exchange_rate_2 = (kurtosis_2)/sqrt(24/NROW(log_return_2))
```

```{r eval=FALSE, warning=FALSE, include=FALSE}
#JB test
JB_test_1 = abs(skewness_exchange_rate_1)*abs(skewness_exchange_rate_1) + abs(kurtosis_exchange_rate_1)*abs(kurtosis_exchange_rate_1)
JB_test_1

JB_test_2 = abs(skewness_exchange_rate_2)*abs(skewness_exchange_rate_2) + abs(kurtosis_exchange_rate_2)*abs(kurtosis_exchange_rate_2)
JB_test_2
```

```{r eval=FALSE, warning=FALSE, include=FALSE}
# Test for Serial Correlation
Box.test(log_return_1, lag = 12, type = "Ljung")
# Test for Serial Correlation
Box.test(log_return_2, lag = 12, type = "Ljung")
```

```{r eval=FALSE, warning=FALSE, include=FALSE}
library(urca) 
library(fUnitRoots)
adfTest(log_return_1, lags= 20)

adfTest(log_return_2, lags= 20)
```

```{r eval=FALSE, warning=FALSE, include=FALSE}
log1_diff_1 = diff(log_return_1)
Dplot_1 = ts(log1_diff_1, frequency=365, start =c(2015,1))
acf(Dplot_1)
pacf(Dplot_1)
adfTest(log1_diff_1, lags = 20)
```

```{r eval=FALSE, warning=FALSE, include=FALSE}
log2_diff_1 = diff(log_return_2)
adfTest(log2_diff_1, lags = 20)
Dplot_2 = ts(log2_diff_1, frequency=365, start =c(2015,1))
acf(Dplot_2)
pacf(Dplot_2)
```

```{r eval=FALSE, warning=FALSE, include=FALSE}
#ARCH-LM test
library(FinTS)
ArchTest(log1_diff_1)

ArchTest(log2_diff_1)
```

```{r eval=FALSE, warning=FALSE, include=FALSE}
#selecting the p,q by eacf test
library(TSA)
eacf(log1_diff_1)
eacf(log2_diff_1)
```

```{r eval=FALSE, warning=FALSE, include=FALSE}
# model fit
model1_1 = arima(log1_diff_1, order = c(1,0,1))
model1_1

model1_2 = arima(log1_diff_1, order = c(0,0,1))
model1_2
```

```{r eval=FALSE, warning=FALSE, include=FALSE}
model2_1 = arima(log2_diff_1, order = c(1,0,1))
model2_1

model2_4 = arima(log2_diff_1, order = c(2,0,2))
model2_4
```

```{r eval=FALSE, warning=FALSE, include=FALSE}
#fitting the GARCH model
library(fGarch)
gm_1 = garchFit( ~ garch(1,0,1), data = log1_diff_1, trace=T)
summary(gm_1)

m1=garchFit(~arma(1,1) +garch(1,0,1), data=log1_diff_1, trace=T)
summary(m1)
```

```{r eval=FALSE, warning=FALSE, include=FALSE}
gm_2 = garchFit( ~ garch(1,0,1), data = log2_diff_1, trace=T)
summary(gm_2)

m2=garchFit(~arma(1,1) +garch(1,0,1), data=log2_diff_1, trace=T)
summary(m2)
```

```{r eval=FALSE, warning=FALSE, include=FALSE}
DATA = cbind(data_1$Marketcap, data_2$Marketcap)

DAT = data.frame(cbind(DATA, log1_diff_1, log2_diff_1))

DA = DAT[ ,c("log1_diff_1", "log2_diff_1")]
```

```{r eval=FALSE, warning=FALSE, include=FALSE}
library(vars)
VARselect(DA)
```

```{r eval=FALSE, warning=FALSE, include=FALSE}
# Test for Granger Causality
library(lmtest)
grangertest(log1_diff_1 ~ log2_diff_1, order = 6, data = DAT)

grangertest(log2_diff_1 ~ log1_diff_1, order = 6, data = DAT)
```

```{r eval=FALSE, warning=FALSE, include=FALSE}
Coint_t <- ca.jo(DA, ecdet = "const", type = "trace", K = 6, spec = "longrun")
summary(Coint_t)

Coint_e = ca.jo(DA, ecdet = "const", type = "eigen", K = 6, spec = "longrun")
summary(Coint_e)
```

```{r eval=FALSE, warning=FALSE, include=FALSE}
library(tsDyn)
tb_eg = VECM(DA,  lag=6,   r= 1,   include="const")
summary(tb_eg)

tb_jo = VECM(DA,  lag=6,   r= 1,   include="const",   estim="ML")
summary(tb_jo)
```

```{r eval=FALSE, warning=FALSE, include=FALSE}
t_eg = lineVar(DA,  lag=6,   r= 1,   model="VECM",   include="const")
summary(t_eg)

t_jo = lineVar(DA,  lag=6,   r= 1,   model="VECM", include="const",   estim="ML")
summary(t_jo)
```

```{r eval=FALSE, warning=FALSE, include=FALSE}
VARrep(t_jo)
```

```{r eval=FALSE, warning=FALSE, include=FALSE}
vecm.pred  =predict(tb_jo,  n.ahead=10)
vecm.pred
pt = ts(vecm.pred)
plot(pt)
```